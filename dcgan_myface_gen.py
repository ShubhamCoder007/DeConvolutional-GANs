# Deep Convolutional GANs

from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
from torch.autograd import Variable
from glob import glob
import cv2

#l = glob('./data/85/*.jpg')
#l = str(l)

# Setting hyperparameters
batchSize = 1 
imageSize = 64 # generated images (64x64).

# Creating the transformations
transform = transforms.Compose([transforms.Scale(imageSize), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) 

# Loading the datas
dataset = dset.ImageFolder(root = './data/data', transform = transform)
#dataset = dset.CIFAR10(root = './data', download = True, transform = transform) 
dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2) # We use dataLoader to get the images of the training set batch by batch.

# Defining the weights function
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)

# Defining the generator

class G(nn.Module): 

    def __init__(self): 
        super(G, self).__init__() 
        self.main = nn.Sequential( 
            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False), 
            nn.BatchNorm2d(512), 
            nn.ReLU(True), 
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False), 
            nn.BatchNorm2d(256), 
            nn.ReLU(True), 
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False), 
            nn.BatchNorm2d(128), 
            nn.ReLU(True), 
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),
            nn.BatchNorm2d(64), 
            nn.ReLU(True), 
            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False), 
            nn.Tanh()
        )

    def forward(self, input): 
        output = self.main(input) 
        return output 

    #def saved(self):
     #   self.save('weights_85.hdf5')
        
        
# Creating the generator
netG = G() # We create the generator object.
netG.apply(weights_init) # We initialize all the weights of its neural network.

netG.save

# Defining the discriminator

class D(nn.Module): 

    def __init__(self): 
        super(D, self).__init__() 
        self.main = nn.Sequential( 
            nn.Conv2d(3, 64, 4, 2, 1, bias = False), 
            nn.LeakyReLU(0.2, inplace = True), 
            nn.Conv2d(64, 128, 4, 2, 1, bias = False), 
            nn.BatchNorm2d(128), 
            nn.LeakyReLU(0.2, inplace = True), 
            nn.Conv2d(128, 256, 4, 2, 1, bias = False), 
            nn.BatchNorm2d(256), # We normalize
            nn.LeakyReLU(0.2, inplace = True), 
            nn.Conv2d(256, 512, 4, 2, 1, bias = False), 
            nn.BatchNorm2d(512), 
            nn.LeakyReLU(0.2, inplace = True), 
            nn.Conv2d(512, 1, 4, 1, 0, bias = False), 
            nn.Sigmoid() # We apply a Sigmoid rectification to break the linearity and stay between 0 and 1.
        )

    def forward(self, input): # input will be a value between 0 and 1.
        output = self.main(input) 
        return output.view(-1) # We return the output which will be a value between 0 and 1.

# Creating the discriminator
netD = D() 
netD.apply(weights_init) 

# Training the DCGANs

criterion = nn.BCELoss() # it will measure the error between the prediction and the target.
optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999)) #  optimizer object of the discriminator.
optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999)) #  optimizer object of the generator.

for epoch in range(25): 

    for i, data in enumerate(dataloader, 0): # We iterate over the images of the dataset.
        
        # Updating the weights of the neural network of the discriminator

        netD.zero_grad() # We initialize to 0 the gradients of the discriminator with respect to the weights.
        
        # Training the discriminator with a real image of the dataset
        real, _ = data # real image of the dataset which will be used to train the discriminator.
        input = Variable(real) 
        target = Variable(torch.ones(input.size()[0])) 
        output = netD(input) # forward propagate this real image into the neural network of the discriminator to get the prediction.
        errD_real = criterion(output, target) # We compute the loss between the predictions and the target.
        
        # Training the discriminator with a fake image generated by the generator
        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)) # We make a random input vector.
        fake = netG(noise) 
        target = Variable(torch.zeros(input.size()[0])) 
        output = netD(fake.detach())
        errD_fake = criterion(output, target) 

        # Backpropagating the total error
        errD = errD_real + errD_fake # compute the total error of the discriminator.
        errD.backward() # backpropagate the loss error by computing the gradients of the total error with respect to the weights of the discriminator.
        optimizerD.step() # apply the optimizer to update the weights according to how much they are responsible for the loss error of the discriminator.

        # Updating the weights of the neural network of the generator

        netG.zero_grad() 
        target = Variable(torch.ones(input.size()[0])) 
        output = netD(fake) 
        errG = criterion(output, target) 
        errG.backward() 
        optimizerG.step() 
        
        # Printing the losses and saving the images

        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), errD.data, errG.data)) # We print les losses of the discriminator (Loss_D) and the generator (Loss_G).
        if i % 1 == 0: # Every 100 steps:
            vutils.save_image(real, '%s/real_samples.png' % "./results", normalize = True) # We save the real images of the minibatch.
            fake = netG(noise) # We get our fake generated images.
            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % ("./results", epoch), normalize = True) # We also save the fake generated images of the minibatch.
            
      
            
#netG.saved()
#g = netG.to(tensor)
new_pic = netG(Variable(torch.randn(input.size()[0], 100, 1, 1)))
vutils.save_image(fake.data, '%s/new_generated%03d.png' % ("./results", epoch), normalize = True)
#cv2.imshow('new_generated021.png',1)